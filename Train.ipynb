{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in d:\\sarvgya\\.venv\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in d:\\sarvgya\\.venv\\lib\\site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: torchaudio in d:\\sarvgya\\.venv\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\sarvgya\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in d:\\sarvgya\\.venv\\lib\\site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\sarvgya\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\sarvgya\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\sarvgya\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\sarvgya\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\sarvgya\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import gym_chess\n",
    "import os\n",
    "import chess\n",
    "from tqdm import tqdm\n",
    "from gym_chess.alphazero.move_encoding import utils\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if cuda available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper methods:\n",
    "\n",
    "#decoding moves from idx to uci notation\n",
    "def _decodeKnight(action: int) -> Optional[chess.Move]:\n",
    "    _NUM_TYPES: int = 8\n",
    "\n",
    "    #: Starting point of knight moves in last dimension of 8 x 8 x 73 action array.\n",
    "    _TYPE_OFFSET: int = 56\n",
    "\n",
    "    #: Set of possible directions for a knight move, encoded as \n",
    "    #: (delta rank, delta square).\n",
    "    _DIRECTIONS = utils.IndexedTuple(\n",
    "        (+2, +1),\n",
    "        (+1, +2),\n",
    "        (-1, +2),\n",
    "        (-2, +1),\n",
    "        (-2, -1),\n",
    "        (-1, -2),\n",
    "        (+1, -2),\n",
    "        (+2, -1),\n",
    "    )\n",
    "\n",
    "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
    "\n",
    "    is_knight_move = (\n",
    "        _TYPE_OFFSET <= move_type\n",
    "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
    "    )\n",
    "\n",
    "    if not is_knight_move:\n",
    "        return None\n",
    "\n",
    "    knight_move_type = move_type - _TYPE_OFFSET\n",
    "\n",
    "    delta_rank, delta_file = _DIRECTIONS[knight_move_type]\n",
    "\n",
    "    to_rank = from_rank + delta_rank\n",
    "    to_file = from_file + delta_file\n",
    "\n",
    "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
    "    return move\n",
    "\n",
    "def _decodeQueen(action: int) -> Optional[chess.Move]:\n",
    "\n",
    "    _NUM_TYPES: int = 56 # = 8 directions * 7 squares max. distance\n",
    "\n",
    "    #: Set of possible directions for a queen move, encoded as \n",
    "    #: (delta rank, delta square).\n",
    "    _DIRECTIONS = utils.IndexedTuple(\n",
    "        (+1,  0),\n",
    "        (+1, +1),\n",
    "        ( 0, +1),\n",
    "        (-1, +1),\n",
    "        (-1,  0),\n",
    "        (-1, -1),\n",
    "        ( 0, -1),\n",
    "        (+1, -1),\n",
    "    )\n",
    "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
    "    \n",
    "    is_queen_move = move_type < _NUM_TYPES\n",
    "\n",
    "    if not is_queen_move:\n",
    "        return None\n",
    "\n",
    "    direction_idx, distance_idx = np.unravel_index(\n",
    "        indices=move_type,\n",
    "        shape=(8,7)\n",
    "    )\n",
    "\n",
    "    direction = _DIRECTIONS[direction_idx]\n",
    "    distance = distance_idx + 1\n",
    "\n",
    "    delta_rank = direction[0] * distance\n",
    "    delta_file = direction[1] * distance\n",
    "\n",
    "    to_rank = from_rank + delta_rank\n",
    "    to_file = from_file + delta_file\n",
    "\n",
    "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
    "    return move\n",
    "\n",
    "def _decodeUnderPromotion(action):\n",
    "    _NUM_TYPES: int = 9 # = 3 directions * 3 piece types (see below)\n",
    "\n",
    "    #: Starting point of underpromotions in last dimension of 8 x 8 x 73 action \n",
    "    #: array.\n",
    "    _TYPE_OFFSET: int = 64\n",
    "\n",
    "    #: Set of possibel directions for an underpromotion, encoded as file delta.\n",
    "    _DIRECTIONS = utils.IndexedTuple(\n",
    "        -1,\n",
    "        0,\n",
    "        +1,\n",
    "    )\n",
    "\n",
    "    #: Set of possibel piece types for an underpromotion (promoting to a queen\n",
    "    #: is implicitly encoded by the corresponding queen move).\n",
    "    _PROMOTIONS = utils.IndexedTuple(\n",
    "        chess.KNIGHT,\n",
    "        chess.BISHOP,\n",
    "        chess.ROOK,\n",
    "    )\n",
    "\n",
    "    from_rank, from_file, move_type = np.unravel_index(action, (8, 8, 73))\n",
    "\n",
    "    is_underpromotion = (\n",
    "        _TYPE_OFFSET <= move_type\n",
    "        and move_type < _TYPE_OFFSET + _NUM_TYPES\n",
    "    )\n",
    "\n",
    "    if not is_underpromotion:\n",
    "        return None\n",
    "\n",
    "    underpromotion_type = move_type - _TYPE_OFFSET\n",
    "\n",
    "    direction_idx, promotion_idx = np.unravel_index(\n",
    "        indices=underpromotion_type,\n",
    "        shape=(3,3)\n",
    "    )\n",
    "\n",
    "    direction = _DIRECTIONS[direction_idx]\n",
    "    promotion = _PROMOTIONS[promotion_idx]\n",
    "\n",
    "    to_rank = from_rank + 1\n",
    "    to_file = from_file + direction\n",
    "\n",
    "    move = utils.pack(from_rank, from_file, to_rank, to_file)\n",
    "    move.promotion = promotion\n",
    "\n",
    "    return move\n",
    "\n",
    "#primary decoding function, the ones above are just helper functions\n",
    "def decodeMove(action: int, board) -> chess.Move:\n",
    "        move = _decodeQueen(action)\n",
    "        is_queen_move = move is not None\n",
    "\n",
    "        if not move:\n",
    "            move = _decodeKnight(action)\n",
    "\n",
    "        if not move:\n",
    "            move = _decodeUnderPromotion(action)\n",
    "\n",
    "        if not move:\n",
    "            raise ValueError(f\"{action} is not a valid action\")\n",
    "\n",
    "        # Actions encode moves from the perspective of the current player. If\n",
    "        # this is the black player, the move must be reoriented.\n",
    "        turn = board.turn\n",
    "        \n",
    "        if turn == False: #black to move\n",
    "            move = utils.rotate(move)\n",
    "\n",
    "        # Moving a pawn to the opponent's home rank with a queen move\n",
    "        # is automatically assumed to be queen underpromotion. However,\n",
    "        # since queenmoves has no reference to the board and can thus not\n",
    "        # determine whether the moved piece is a pawn, you have to add this\n",
    "        # information manually here\n",
    "        if is_queen_move:\n",
    "            to_rank = chess.square_rank(move.to_square)\n",
    "            is_promoting_move = (\n",
    "                (to_rank == 7 and turn == True) or \n",
    "                (to_rank == 0 and turn == False)\n",
    "            )\n",
    "\n",
    "            piece = board.piece_at(move.from_square)\n",
    "            if piece is None: #NOTE I added this, not entirely sure if it's correct\n",
    "                return None\n",
    "            is_pawn = piece.piece_type == chess.PAWN\n",
    "\n",
    "            if is_pawn and is_promoting_move:\n",
    "                move.promotion = chess.QUEEN\n",
    "\n",
    "        return move\n",
    "\n",
    "def encodeBoard(board: chess.Board) -> np.array:\n",
    " \"\"\"Converts a board to numpy array representation.\"\"\"\n",
    "\n",
    " array = np.zeros((8, 8, 14), dtype=int)\n",
    "\n",
    " for square, piece in board.piece_map().items():\n",
    "  rank, file = chess.square_rank(square), chess.square_file(square)\n",
    "  piece_type, color = piece.piece_type, piece.color\n",
    " \n",
    "  # The first six planes encode the pieces of the active player, \n",
    "  # the following six those of the active player's opponent. Since\n",
    "  # this class always stores boards oriented towards the white player,\n",
    "  # White is considered to be the active player here.\n",
    "  offset = 0 if color == chess.WHITE else 6\n",
    "  \n",
    "  # Chess enumerates piece types beginning with one, which you have\n",
    "  # to account for\n",
    "  idx = piece_type - 1\n",
    " \n",
    "  array[rank, file, idx + offset] = 1\n",
    "\n",
    " # Repetition counters\n",
    " array[:, :, 12] = board.is_repetition(2)\n",
    " array[:, :, 13] = board.is_repetition(3)\n",
    "\n",
    " return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRACTION_OF_DATA = 1\n",
    "BATCH_SIZE = 4\n",
    "#fraction of data vairable is there just in case you want to train the model fast and do no want to train it on the full data set, (>0 <=1)\n",
    "#Batch sixe variable decides the batch size the model trains on. higher batch size model train faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "#loading training data\n",
    "\n",
    "allMoves = []\n",
    "allBoards = []\n",
    "\n",
    "files = os.listdir('data/PreparedData')\n",
    "numOfEach = len(files) // 2 # half are moves, other half are positions\n",
    "\n",
    "for i in range(numOfEach):\n",
    "    try:\n",
    "        moves = np.load(f\"data/PreparedData/moves{i}.npy\", allow_pickle=True)\n",
    "        boards = np.load(f\"data/PreparedData/positions{i}.npy\", allow_pickle=True)\n",
    "        if (len(moves) != len(boards)):\n",
    "            print(\"ERROR ON i = \", i, len(moves), len(boards))\n",
    "        allMoves.extend(moves)\n",
    "        allBoards.extend(boards)\n",
    "    except:\n",
    "        print(\"error: could not load \", i, \", but is still going\")\n",
    "\n",
    "allMoves = np.array(allMoves)[:(int(len(allMoves) * FRACTION_OF_DATA))]\n",
    "allBoards = np.array(allBoards)[:(int(len(allBoards) * FRACTION_OF_DATA))]\n",
    "assert len(allMoves) == len(allBoards), \"MUST BE OF SAME LENGTH\"\n",
    "\n",
    "#flatten out boards\n",
    "# allBoards = allBoards.reshape(allBoards.shape[0], -1)\n",
    "\n",
    "trainDataIdx = int(len(allMoves) * 0.8)\n",
    "\n",
    "#NOTE transfer all data to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "allBoards = torch.from_numpy(np.asarray(allBoards)).to(device)\n",
    "allMoves = torch.from_numpy(np.asarray(allMoves)).to(device)\n",
    "\n",
    "training_set = torch.utils.data.TensorDataset(allBoards[:trainDataIdx], allMoves[:trainDataIdx])\n",
    "test_set = torch.utils.data.TensorDataset(allBoards[trainDataIdx:], allMoves[trainDataIdx:])\n",
    "# Create data loaders for your datasets; shuffle for training, not for validation\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.INPUT_SIZE = 896 \n",
    "        # self.INPUT_SIZE = 7*7*13 #NOTE changing input size for using cnns\n",
    "        self.OUTPUT_SIZE = 4672 # = number of unique moves (action space)\n",
    "        \n",
    "        #can try to add CNN and pooling here (calculations taking into account spacial features)\n",
    "\n",
    "        #input shape for sample is (8,8,14), flattened to 1d array of size 896\n",
    "        # self.cnn1 = nn.Conv3d(4,4,(2,2,4), padding=(0,0,1))\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(self.INPUT_SIZE, 1000)\n",
    "        self.linear2 = torch.nn.Linear(1000, 1000)\n",
    "        self.linear3 = torch.nn.Linear(1000, 1000)\n",
    "        self.linear4 = torch.nn.Linear(1000, 200)\n",
    "        self.linear5 = torch.nn.Linear(200, self.OUTPUT_SIZE)\n",
    "        self.softmax = torch.nn.Softmax(1) #use softmax as prob for each move, dim 1 as dim 0 is the batch dimension\n",
    " \n",
    "    def forward(self, x): #x.shape = (batch size, 896)\n",
    "        x = x.to(torch.float32)\n",
    "        # x = self.cnn1(x) #for using cnns\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear5(x)\n",
    "        # x = self.softmax(x) #do not use softmax since you are using cross entropy loss\n",
    "        return x\n",
    "\n",
    "    def predict(self, board : chess.Board):\n",
    "        \"\"\"takes in a chess board and returns a chess.move object. NOTE: this function should definitely be written better, but it works for now\"\"\"\n",
    "        with torch.no_grad():\n",
    "            encodedBoard = encodeBoard(board)\n",
    "            encodedBoard = encodedBoard.reshape(1, -1)\n",
    "            encodedBoard = torch.from_numpy(encodedBoard)\n",
    "            res = self.forward(encodedBoard)\n",
    "            probs = self.softmax(res)\n",
    "\n",
    "            probs = probs.numpy()[0] #do not want tensor anymore, 0 since it is a 2d array with 1 row\n",
    "\n",
    "            #verify that move is legal and can be decoded before returning\n",
    "            while len(probs) > 0: #try max 100 times, if not throw an error\n",
    "                moveIdx = probs.argmax()\n",
    "                try: #TODO should not have try here, but was a bug with idx 499 if it is black to move\n",
    "                    uciMove = decodeMove(moveIdx, board)\n",
    "                    if (uciMove is None): #could not decode\n",
    "                        probs = np.delete(probs, moveIdx)\n",
    "                        continue\n",
    "                    move = chess.Move.from_uci(str(uciMove))\n",
    "                    if (move in board.legal_moves): #if legal, return, else: loop continues after deleting the move\n",
    "                        return move \n",
    "                except:\n",
    "                    pass\n",
    "                probs = np.delete(probs, moveIdx) #TODO probably better way to do this, but it is not too time critical as it is only for predictions\n",
    "                                             #remove the move so its not chosen again next iteration\n",
    "            \n",
    "            #TODO can return random move here as well!\n",
    "            return None #if no legal moves found, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for training\n",
    "def train_one_epoch(model, optimizer, loss_fn, epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, you use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that you can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            # print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "#the 3 functions below help store the best model you have created yet\n",
    "def createBestModelFile():\n",
    "    #first find best model if it exists:\n",
    "    folderPath = Path('./savedModels')\n",
    "    if (not folderPath.exists()):\n",
    "        os.mkdir(folderPath)\n",
    "\n",
    "    path = Path('./savedModels/bestModel.txt')\n",
    "\n",
    "    if (not path.exists()):\n",
    "        #create the files\n",
    "        f = open(path, \"w\")\n",
    "        f.write(\"10000000\") #set to high number so it is overwritten with better loss\n",
    "        f.write(\"\\ntestPath\")\n",
    "        f.close()\n",
    "\n",
    "def saveBestModel(vloss, pathToBestModel):\n",
    "    f = open(\"./savedModels/bestModel.txt\", \"w\")\n",
    "    f.write(str(vloss.item()))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(pathToBestModel)\n",
    "    print(\"NEW BEST MODEL FOUND WITH LOSS:\", vloss)\n",
    "\n",
    "def retrieveBestModelInfo():\n",
    "    f = open('./savedModels/bestModel.txt', \"r\")\n",
    "    bestLoss = float(f.readline())\n",
    "    bestModelPath = f.readline()\n",
    "    f.close()\n",
    "    return bestLoss, bestModelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [00:00<00:12,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 8.456425666809082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [00:00<00:07,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6:\n",
      "LOSS train 0.0 valid 8.456908226013184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [00:01<00:05,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11:\n",
      "LOSS train 0.0 valid 8.457098007202148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16/60 [00:02<00:05,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 16:\n",
      "LOSS train 0.0 valid 8.457221984863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 21/60 [00:02<00:04,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 21:\n",
      "LOSS train 0.0 valid 8.457503318786621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 26/60 [00:03<00:04,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 26:\n",
      "LOSS train 0.0 valid 8.457804679870605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 31/60 [00:04<00:03,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 31:\n",
      "LOSS train 0.0 valid 8.45822525024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 36/60 [00:04<00:03,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 36:\n",
      "LOSS train 0.0 valid 8.458868980407715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 41/60 [00:05<00:02,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 41:\n",
      "LOSS train 0.0 valid 8.460022926330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 46/60 [00:05<00:01,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 46:\n",
      "LOSS train 0.0 valid 8.46351432800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 51/60 [00:06<00:01,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 51:\n",
      "LOSS train 0.0 valid 8.505102157592773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 56/60 [00:07<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 56:\n",
      "LOSS train 0.0 valid 8.785257339477539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:07<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BEST VALIDATION LOSS FOR ALL MODELS:  8.37604808807373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#run training\n",
    "\n",
    "createBestModelFile()\n",
    "\n",
    "bestLoss, bestModelPath = retrieveBestModelInfo()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "model = Model()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    if (epoch_number % 5 == 0):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(model, optimizer, loss_fn, epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "\n",
    "    #only print every 5 epochs\n",
    "    if epoch_number % 5 == 0:\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "\n",
    "        if (bestLoss > best_vloss): #if better than previous best loss from all models created, save it\n",
    "            model_path = 'savedModels/model_{}_{}'.format(timestamp, epoch_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            saveBestModel(best_vloss, model_path)\n",
    "\n",
    "    epoch_number += 1\n",
    "\n",
    "print(\"\\n\\nBEST VALIDATION LOSS FOR ALL MODELS: \", bestLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
